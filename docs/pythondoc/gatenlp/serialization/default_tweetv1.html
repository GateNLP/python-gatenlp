<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>gatenlp.serialization.default_tweetv1 API documentation</title>
<meta name="description" content="Module that implements the various ways of how to save and load documents and change logs." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gatenlp.serialization.default_tweetv1</code></h1>
</header>
<section id="section-intro">
<p>Module that implements the various ways of how to save and load documents and change logs.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Module that implements the various ways of how to save and load documents and change logs.
&#34;&#34;&#34;
from collections import defaultdict
from gatenlp.document import Document
from gatenlp.utils import get_nested
from gatenlp.urlfileutils import is_url, get_str_from_url, get_bytes_from_url
import json

JSON_WRITE = &#34;wt&#34;
JSON_READ = &#34;rt&#34;

TWITTER_DEFAULT_INCLUDE_FIELDS = [
    &#34;id_str&#34;,
    &#34;user.id_str&#34;,
    &#34;user.screen_name&#34;,
    &#34;user.name&#34; &#34;created_at&#34;,
    &#34;is_quote_status&#34;,
    &#34;quote_count&#34;,
    &#34;retweet_count&#34;,
    &#34;favourite_count&#34;,
    &#34;favourited&#34;,
    &#34;retweeted&#34;,
    &#34;lang&#34;,
    &#34;$is_retweet_status&#34;,
    &#34;retweeted_status.user.screen_name&#34;,
]


class TweetV1Serializer:

    @staticmethod
    def doc2twitterv1dict(doc, annspec=None, prefix_sep=None):
        d = doc.to_dict(annspec=annspec)
        ret = {&#34;full_text&#34;: doc.text}
        ents = defaultdict(list)
        for setname, annset in d.get(&#34;annotation_sets&#34;, {}).items():
            for ann in annset.get(&#34;annotations&#34;, []):
                anntype = ann[&#34;type&#34;]
                if prefix_sep is not None and setname != &#34;&#34;:
                    anntype = setname + prefix_sep + anntype
                annlist = ents[anntype]
                twitterann = {
                    &#34;indices&#34;: [ann[&#34;start&#34;], ann[&#34;end&#34;]]
                }
                twitterann.update(ann[&#34;features&#34;])
                annlist.append(twitterann)
        ret[&#34;entities&#34;] = ents
        return ret

    @staticmethod
    def save(
        clazz,
        inst,
        to_ext=None,
        to_mem=None,
        annspec=None,
        prefix_sep=None,
        **kwargs,
    ):
        &#34;&#34;&#34;

        Args:
            clazz: the class of the object that gets saved
            inst: the object to get saved
            to_ext: where to save to, this should be a file path, only one of to_ext and to_mem should be specified
            to_mem: if True, return a String serialization
            offset_type: the offset type to use for saving, if None (default) use &#34;p&#34; (Python)
            offset_mapper: the offset mapper to use, only needed if the type needs to get converted
            annspec: which annotation sets and types to include, list of set names or (setanmes, types) tuples
            prefix_types: if not None, prefix all types with the name of the annotation set the annotation comes from
                and use the given string as the separator (can be the empty string for no seaparator).
                For annotations from the default set the type stays unchanged.
          **kwargs:
        &#34;&#34;&#34;
        d = TweetV1Serializer.doc2twitterv1dict(inst, annspec=annspec, prefix_sep=prefix_sep)
        if to_mem:
            return json.dumps(d)
        else:
            with open(to_ext, JSON_WRITE) as outfp:
                json.dump(d, outfp)

    @staticmethod
    def load(
        clazz,
        from_ext=None,
        from_mem=None,
        include_fields=None,
        include_entities=True,
        include_quote=False,
        outsetname=&#34;Original markups&#34;,
        tweet_ann=&#34;Tweet&#34;,
    ):
        &#34;&#34;&#34;
        Load a tweet from Twitter JSON format.

        IMPORTANT: this is still very experimental, will change in the future!

        Args:
            clazz: internal use
            from_ext: the file/url to load from
            from_mem: string to load from
            include_fields: a list of fields to include where nested field names are dot-separated, e.g.
               &#34;user.location&#34;. All these fields are included using the nested field name in either the
               features of the tweet annotation with the Type specified, or the features of the document
               if `tweet_ann` is None.
            include_entities: create annotations for the tweet entities in the set with outsetname
            include_quote: if True, add the quoted tweet after an empty line and treat it as a separate
               tweet just like the original tweet.
            outset: the annotation set where to put entity annotations and the tweet annotation(s)
            tweet_ann: the annotation type to use to span the tweet and contain all the features.

        Returns:
            document representing the tweet
        &#34;&#34;&#34;
        if from_ext is not None:
            isurl, extstr = is_url(from_ext)
            if isurl:
                jsonstr = get_str_from_url(extstr, encoding=&#34;utf-8&#34;)
                tweet = json.loads(jsonstr)
            else:
                with open(extstr, &#34;rt&#34;, encoding=&#34;utf-8&#34;) as infp:
                    tweet = json.load(infp)
        elif from_mem is not None:
            tweet = json.loads(from_mem)
        else:
            raise Exception(&#34;Cannot load from None&#34;)
        if tweet is None:
            raise Exception(&#34;Could not decode Tweet JSON&#34;)
        if tweet.get(&#34;truncated&#34;):
            text = get_nested(tweet, &#34;extended_tweet.full_text&#34;)
        else:
            text = get_nested(tweet, &#34;text&#34;)
        if text is None:
            raise Exception(&#34;No text field found&#34;)
        quoted_status = None
        if include_quote:
            quoted_status = tweet.get(&#34;quoted_status&#34;)
            if quoted_status is not None:
                qtext = quoted_status.get(&#34;text&#34;, &#34;&#34;)
                text += &#34;\n&#34; + qtext
        doc = Document(text)
        anns = doc.annset(outsetname)
        if tweet_ann:
            ann = anns.add(0, len(text), tweet_ann)
            features = ann.features
        else:
            features = doc.features
        if include_fields is None:
            include_fields = TWITTER_DEFAULT_INCLUDE_FIELDS
        for field in include_fields:
            if field.startswith(&#34;$&#34;):
                if field == &#34;$is_retweet_status&#34;:
                    rs = get_nested(tweet, &#34;retweeted_status&#34;, silent=True)
                    if rs is not None:
                        features[field] = True
                continue
            val = get_nested(tweet, field, silent=True)
            if val is not None:
                features[field] = val
        if include_entities:
            if tweet.get(&#34;truncated&#34;):
                entities = get_nested(tweet, &#34;extended_tweet.entities&#34;, default={})
            else:
                entities = get_nested(tweet, &#34;entities&#34;, default={})
        for etype, elist in entities.items():
            for ent in elist:
                start, end = ent[&#34;indices&#34;]
                anns.add(start, end, etype)
        # TODO: if we have a quoted_status, add features and entities from there:
        # Essentially the same processing as for the original tweet, but at document offset
        # len(tweet)+1 (2?)
        return doc</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="gatenlp.serialization.default_tweetv1.TweetV1Serializer"><code class="flex name class">
<span>class <span class="ident">TweetV1Serializer</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TweetV1Serializer:

    @staticmethod
    def doc2twitterv1dict(doc, annspec=None, prefix_sep=None):
        d = doc.to_dict(annspec=annspec)
        ret = {&#34;full_text&#34;: doc.text}
        ents = defaultdict(list)
        for setname, annset in d.get(&#34;annotation_sets&#34;, {}).items():
            for ann in annset.get(&#34;annotations&#34;, []):
                anntype = ann[&#34;type&#34;]
                if prefix_sep is not None and setname != &#34;&#34;:
                    anntype = setname + prefix_sep + anntype
                annlist = ents[anntype]
                twitterann = {
                    &#34;indices&#34;: [ann[&#34;start&#34;], ann[&#34;end&#34;]]
                }
                twitterann.update(ann[&#34;features&#34;])
                annlist.append(twitterann)
        ret[&#34;entities&#34;] = ents
        return ret

    @staticmethod
    def save(
        clazz,
        inst,
        to_ext=None,
        to_mem=None,
        annspec=None,
        prefix_sep=None,
        **kwargs,
    ):
        &#34;&#34;&#34;

        Args:
            clazz: the class of the object that gets saved
            inst: the object to get saved
            to_ext: where to save to, this should be a file path, only one of to_ext and to_mem should be specified
            to_mem: if True, return a String serialization
            offset_type: the offset type to use for saving, if None (default) use &#34;p&#34; (Python)
            offset_mapper: the offset mapper to use, only needed if the type needs to get converted
            annspec: which annotation sets and types to include, list of set names or (setanmes, types) tuples
            prefix_types: if not None, prefix all types with the name of the annotation set the annotation comes from
                and use the given string as the separator (can be the empty string for no seaparator).
                For annotations from the default set the type stays unchanged.
          **kwargs:
        &#34;&#34;&#34;
        d = TweetV1Serializer.doc2twitterv1dict(inst, annspec=annspec, prefix_sep=prefix_sep)
        if to_mem:
            return json.dumps(d)
        else:
            with open(to_ext, JSON_WRITE) as outfp:
                json.dump(d, outfp)

    @staticmethod
    def load(
        clazz,
        from_ext=None,
        from_mem=None,
        include_fields=None,
        include_entities=True,
        include_quote=False,
        outsetname=&#34;Original markups&#34;,
        tweet_ann=&#34;Tweet&#34;,
    ):
        &#34;&#34;&#34;
        Load a tweet from Twitter JSON format.

        IMPORTANT: this is still very experimental, will change in the future!

        Args:
            clazz: internal use
            from_ext: the file/url to load from
            from_mem: string to load from
            include_fields: a list of fields to include where nested field names are dot-separated, e.g.
               &#34;user.location&#34;. All these fields are included using the nested field name in either the
               features of the tweet annotation with the Type specified, or the features of the document
               if `tweet_ann` is None.
            include_entities: create annotations for the tweet entities in the set with outsetname
            include_quote: if True, add the quoted tweet after an empty line and treat it as a separate
               tweet just like the original tweet.
            outset: the annotation set where to put entity annotations and the tweet annotation(s)
            tweet_ann: the annotation type to use to span the tweet and contain all the features.

        Returns:
            document representing the tweet
        &#34;&#34;&#34;
        if from_ext is not None:
            isurl, extstr = is_url(from_ext)
            if isurl:
                jsonstr = get_str_from_url(extstr, encoding=&#34;utf-8&#34;)
                tweet = json.loads(jsonstr)
            else:
                with open(extstr, &#34;rt&#34;, encoding=&#34;utf-8&#34;) as infp:
                    tweet = json.load(infp)
        elif from_mem is not None:
            tweet = json.loads(from_mem)
        else:
            raise Exception(&#34;Cannot load from None&#34;)
        if tweet is None:
            raise Exception(&#34;Could not decode Tweet JSON&#34;)
        if tweet.get(&#34;truncated&#34;):
            text = get_nested(tweet, &#34;extended_tweet.full_text&#34;)
        else:
            text = get_nested(tweet, &#34;text&#34;)
        if text is None:
            raise Exception(&#34;No text field found&#34;)
        quoted_status = None
        if include_quote:
            quoted_status = tweet.get(&#34;quoted_status&#34;)
            if quoted_status is not None:
                qtext = quoted_status.get(&#34;text&#34;, &#34;&#34;)
                text += &#34;\n&#34; + qtext
        doc = Document(text)
        anns = doc.annset(outsetname)
        if tweet_ann:
            ann = anns.add(0, len(text), tweet_ann)
            features = ann.features
        else:
            features = doc.features
        if include_fields is None:
            include_fields = TWITTER_DEFAULT_INCLUDE_FIELDS
        for field in include_fields:
            if field.startswith(&#34;$&#34;):
                if field == &#34;$is_retweet_status&#34;:
                    rs = get_nested(tweet, &#34;retweeted_status&#34;, silent=True)
                    if rs is not None:
                        features[field] = True
                continue
            val = get_nested(tweet, field, silent=True)
            if val is not None:
                features[field] = val
        if include_entities:
            if tweet.get(&#34;truncated&#34;):
                entities = get_nested(tweet, &#34;extended_tweet.entities&#34;, default={})
            else:
                entities = get_nested(tweet, &#34;entities&#34;, default={})
        for etype, elist in entities.items():
            for ent in elist:
                start, end = ent[&#34;indices&#34;]
                anns.add(start, end, etype)
        # TODO: if we have a quoted_status, add features and entities from there:
        # Essentially the same processing as for the original tweet, but at document offset
        # len(tweet)+1 (2?)
        return doc</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="gatenlp.serialization.default_tweetv1.TweetV1Serializer.doc2twitterv1dict"><code class="name flex">
<span>def <span class="ident">doc2twitterv1dict</span></span>(<span>doc, annspec=None, prefix_sep=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def doc2twitterv1dict(doc, annspec=None, prefix_sep=None):
    d = doc.to_dict(annspec=annspec)
    ret = {&#34;full_text&#34;: doc.text}
    ents = defaultdict(list)
    for setname, annset in d.get(&#34;annotation_sets&#34;, {}).items():
        for ann in annset.get(&#34;annotations&#34;, []):
            anntype = ann[&#34;type&#34;]
            if prefix_sep is not None and setname != &#34;&#34;:
                anntype = setname + prefix_sep + anntype
            annlist = ents[anntype]
            twitterann = {
                &#34;indices&#34;: [ann[&#34;start&#34;], ann[&#34;end&#34;]]
            }
            twitterann.update(ann[&#34;features&#34;])
            annlist.append(twitterann)
    ret[&#34;entities&#34;] = ents
    return ret</code></pre>
</details>
</dd>
<dt id="gatenlp.serialization.default_tweetv1.TweetV1Serializer.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>clazz, from_ext=None, from_mem=None, include_fields=None, include_entities=True, include_quote=False, outsetname='Original markups', tweet_ann='Tweet')</span>
</code></dt>
<dd>
<div class="desc"><p>Load a tweet from Twitter JSON format.</p>
<p>IMPORTANT: this is still very experimental, will change in the future!</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>clazz</code></strong></dt>
<dd>internal use</dd>
<dt><strong><code>from_ext</code></strong></dt>
<dd>the file/url to load from</dd>
<dt><strong><code>from_mem</code></strong></dt>
<dd>string to load from</dd>
<dt><strong><code>include_fields</code></strong></dt>
<dd>a list of fields to include where nested field names are dot-separated, e.g.
"user.location". All these fields are included using the nested field name in either the
features of the tweet annotation with the Type specified, or the features of the document
if <code>tweet_ann</code> is None.</dd>
<dt><strong><code>include_entities</code></strong></dt>
<dd>create annotations for the tweet entities in the set with outsetname</dd>
<dt><strong><code>include_quote</code></strong></dt>
<dd>if True, add the quoted tweet after an empty line and treat it as a separate
tweet just like the original tweet.</dd>
<dt><strong><code>outset</code></strong></dt>
<dd>the annotation set where to put entity annotations and the tweet annotation(s)</dd>
<dt><strong><code>tweet_ann</code></strong></dt>
<dd>the annotation type to use to span the tweet and contain all the features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>document representing the tweet</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def load(
    clazz,
    from_ext=None,
    from_mem=None,
    include_fields=None,
    include_entities=True,
    include_quote=False,
    outsetname=&#34;Original markups&#34;,
    tweet_ann=&#34;Tweet&#34;,
):
    &#34;&#34;&#34;
    Load a tweet from Twitter JSON format.

    IMPORTANT: this is still very experimental, will change in the future!

    Args:
        clazz: internal use
        from_ext: the file/url to load from
        from_mem: string to load from
        include_fields: a list of fields to include where nested field names are dot-separated, e.g.
           &#34;user.location&#34;. All these fields are included using the nested field name in either the
           features of the tweet annotation with the Type specified, or the features of the document
           if `tweet_ann` is None.
        include_entities: create annotations for the tweet entities in the set with outsetname
        include_quote: if True, add the quoted tweet after an empty line and treat it as a separate
           tweet just like the original tweet.
        outset: the annotation set where to put entity annotations and the tweet annotation(s)
        tweet_ann: the annotation type to use to span the tweet and contain all the features.

    Returns:
        document representing the tweet
    &#34;&#34;&#34;
    if from_ext is not None:
        isurl, extstr = is_url(from_ext)
        if isurl:
            jsonstr = get_str_from_url(extstr, encoding=&#34;utf-8&#34;)
            tweet = json.loads(jsonstr)
        else:
            with open(extstr, &#34;rt&#34;, encoding=&#34;utf-8&#34;) as infp:
                tweet = json.load(infp)
    elif from_mem is not None:
        tweet = json.loads(from_mem)
    else:
        raise Exception(&#34;Cannot load from None&#34;)
    if tweet is None:
        raise Exception(&#34;Could not decode Tweet JSON&#34;)
    if tweet.get(&#34;truncated&#34;):
        text = get_nested(tweet, &#34;extended_tweet.full_text&#34;)
    else:
        text = get_nested(tweet, &#34;text&#34;)
    if text is None:
        raise Exception(&#34;No text field found&#34;)
    quoted_status = None
    if include_quote:
        quoted_status = tweet.get(&#34;quoted_status&#34;)
        if quoted_status is not None:
            qtext = quoted_status.get(&#34;text&#34;, &#34;&#34;)
            text += &#34;\n&#34; + qtext
    doc = Document(text)
    anns = doc.annset(outsetname)
    if tweet_ann:
        ann = anns.add(0, len(text), tweet_ann)
        features = ann.features
    else:
        features = doc.features
    if include_fields is None:
        include_fields = TWITTER_DEFAULT_INCLUDE_FIELDS
    for field in include_fields:
        if field.startswith(&#34;$&#34;):
            if field == &#34;$is_retweet_status&#34;:
                rs = get_nested(tweet, &#34;retweeted_status&#34;, silent=True)
                if rs is not None:
                    features[field] = True
            continue
        val = get_nested(tweet, field, silent=True)
        if val is not None:
            features[field] = val
    if include_entities:
        if tweet.get(&#34;truncated&#34;):
            entities = get_nested(tweet, &#34;extended_tweet.entities&#34;, default={})
        else:
            entities = get_nested(tweet, &#34;entities&#34;, default={})
    for etype, elist in entities.items():
        for ent in elist:
            start, end = ent[&#34;indices&#34;]
            anns.add(start, end, etype)
    # TODO: if we have a quoted_status, add features and entities from there:
    # Essentially the same processing as for the original tweet, but at document offset
    # len(tweet)+1 (2?)
    return doc</code></pre>
</details>
</dd>
<dt id="gatenlp.serialization.default_tweetv1.TweetV1Serializer.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>clazz, inst, to_ext=None, to_mem=None, annspec=None, prefix_sep=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>clazz: the class of the object that gets saved
inst: the object to get saved
to_ext: where to save to, this should be a file path, only one of to_ext and to_mem should be specified
to_mem: if True, return a String serialization
offset_type: the offset type to use for saving, if None (default) use "p" (Python)
offset_mapper: the offset mapper to use, only needed if the type needs to get converted
annspec: which annotation sets and types to include, list of set names or (setanmes, types) tuples
prefix_types: if not None, prefix all types with the name of the annotation set the annotation comes from
and use the given string as the separator (can be the empty string for no seaparator).
For annotations from the default set the type stays unchanged.
**kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def save(
    clazz,
    inst,
    to_ext=None,
    to_mem=None,
    annspec=None,
    prefix_sep=None,
    **kwargs,
):
    &#34;&#34;&#34;

    Args:
        clazz: the class of the object that gets saved
        inst: the object to get saved
        to_ext: where to save to, this should be a file path, only one of to_ext and to_mem should be specified
        to_mem: if True, return a String serialization
        offset_type: the offset type to use for saving, if None (default) use &#34;p&#34; (Python)
        offset_mapper: the offset mapper to use, only needed if the type needs to get converted
        annspec: which annotation sets and types to include, list of set names or (setanmes, types) tuples
        prefix_types: if not None, prefix all types with the name of the annotation set the annotation comes from
            and use the given string as the separator (can be the empty string for no seaparator).
            For annotations from the default set the type stays unchanged.
      **kwargs:
    &#34;&#34;&#34;
    d = TweetV1Serializer.doc2twitterv1dict(inst, annspec=annspec, prefix_sep=prefix_sep)
    if to_mem:
        return json.dumps(d)
    else:
        with open(to_ext, JSON_WRITE) as outfp:
            json.dump(d, outfp)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gatenlp.serialization" href="index.html">gatenlp.serialization</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="gatenlp.serialization.default_tweetv1.TweetV1Serializer" href="#gatenlp.serialization.default_tweetv1.TweetV1Serializer">TweetV1Serializer</a></code></h4>
<ul class="">
<li><code><a title="gatenlp.serialization.default_tweetv1.TweetV1Serializer.doc2twitterv1dict" href="#gatenlp.serialization.default_tweetv1.TweetV1Serializer.doc2twitterv1dict">doc2twitterv1dict</a></code></li>
<li><code><a title="gatenlp.serialization.default_tweetv1.TweetV1Serializer.load" href="#gatenlp.serialization.default_tweetv1.TweetV1Serializer.load">load</a></code></li>
<li><code><a title="gatenlp.serialization.default_tweetv1.TweetV1Serializer.save" href="#gatenlp.serialization.default_tweetv1.TweetV1Serializer.save">save</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>